{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treescope\n",
    "import torchinfo\n",
    "from nutils.benchmark import measure_flops, benchmark_model\n",
    "treescope.register_as_default()\n",
    "treescope.basic_interactive_setup(autovisualize_arrays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDM VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models import AutoencoderKL\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
    "num_params = sum(p.numel() for p in vae.parameters())\n",
    "num_params_encoder = sum(p.numel() for p in vae.encoder.parameters())\n",
    "num_params_decoder = sum(p.numel() for p in vae.decoder.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")\n",
    "print(f\"Number of parameters in the encoder: {num_params_encoder:,}\")\n",
    "print(f\"Number of parameters in the decoder: {num_params_decoder:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae import VAE\n",
    "\n",
    "vae = VAE(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    channels=128,\n",
    "    channels_mult=[1,2,4,4],\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=[],\n",
    "    dropout=0.0,\n",
    "    resolution=256,\n",
    "    z_channels=4,\n",
    "    spatial_compression=8,\n",
    "    prior=\"gaussian\",\n",
    ")\n",
    "num_params = sum(p.numel() for p in vae.parameters())\n",
    "num_params_encoder = sum(p.numel() for p in vae.encoder.parameters())\n",
    "num_params_decoder = sum(p.numel() for p in vae.decoder.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")\n",
    "print(f\"Number of parameters in the encoder: {num_params_encoder:,}\")\n",
    "print(f\"Number of parameters in the decoder: {num_params_decoder:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(\n",
    "    vae,\n",
    "    (1, 3, 256, 256),\n",
    "    depth=1,\n",
    "    col_names=(\n",
    "        \"input_size\",\n",
    "        \"output_size\",\n",
    "        \"num_params\",\n",
    "        \"params_percent\",\n",
    "        \"mult_adds\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = benchmark_model(vae, (2, 3, 256, 256), device=\"cuda\")\n",
    "print(f\"Runtime: {runtime.median:.2f} ms\")\n",
    "\n",
    "flops = measure_flops(vae, (1, 3, 256, 256), device=\"cuda\")\n",
    "print(f\"FLOPs: {flops['forward_total']/1e9:,} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class GRN(nn.Module):\n",
    "    \"\"\"GRN (Global Response Normalization) layer\"\"\"\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Gx = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n",
    "        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
    "        return self.gamma * (x * Nx) + self.beta + x\n",
    "\n",
    "\n",
    "class ConvNeXtBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, *, in_channels: int, out_channels: int = None, dropout: float, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels or in_channels\n",
    "\n",
    "        self.convdw1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=7,\n",
    "            padding=3,\n",
    "            groups=in_channels,\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(in_channels)\n",
    "        self.pwconv1_1 = nn.Linear(in_channels, 2 * in_channels)\n",
    "        self.act1 = nn.GELU()\n",
    "        self.gn1 = GRN(2 * in_channels)\n",
    "        self.pwconv1_2 = nn.Linear(2 * in_channels, in_channels)\n",
    "\n",
    "        self.up_proj = (\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            if in_channels != out_channels\n",
    "            else nn.Identity()\n",
    "        )\n",
    "        self.nin_shortcut = (\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            if in_channels != out_channels\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.convdw1(h)\n",
    "        h = rearrange(h, \"b c h w -> b h w c\")\n",
    "        # h = h.permute()\n",
    "        h = self.norm1(h)\n",
    "        h = self.pwconv1_1(h)\n",
    "        h = self.act1(h)\n",
    "        h = self.gn1(h)\n",
    "        h = self.pwconv1_2(h)\n",
    "        h = rearrange(h, \"b h w c -> b c h w\")\n",
    "\n",
    "        x = self.up_proj(h) + self.nin_shortcut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    channels=128,\n",
    "    channels_mult=[1,2,4,4],\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=[],\n",
    "    dropout=0.0,\n",
    "    resolution=256,\n",
    "    z_channels=4,\n",
    "    spatial_compression=8,\n",
    "    prior=\"gaussian\",\n",
    "    block_fn=ConvNeXtBlock\n",
    ")\n",
    "num_params = sum(p.numel() for p in vae.parameters())\n",
    "num_params_encoder = sum(p.numel() for p in vae.encoder.parameters())\n",
    "num_params_decoder = sum(p.numel() for p in vae.decoder.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")\n",
    "print(f\"Number of parameters in the encoder: {num_params_encoder:,}\")\n",
    "print(f\"Number of parameters in the decoder: {num_params_decoder:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(\n",
    "    vae,\n",
    "    (1, 3, 256, 256),\n",
    "    depth=1,\n",
    "    col_names=(\n",
    "        \"input_size\",\n",
    "        \"output_size\",\n",
    "        \"num_params\",\n",
    "        \"params_percent\",\n",
    "        \"mult_adds\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = benchmark_model(vae, (2, 3, 256, 256), device=\"cuda\")\n",
    "print(f\"Runtime: {runtime.median:.2f} ms\")\n",
    "\n",
    "flops = measure_flops(vae, (1, 3, 256, 256), device=\"cuda\")\n",
    "print(f\"FLOPs: {flops['forward_total']/1e9:,} GFLOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
